{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "469e3105",
   "metadata": {},
   "source": [
    "# SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80737474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def get_authors_from_letter(letter='a'):\n",
    "    \"\"\"\n",
    "    Extracts authors from Project Gutenberg for a specific letter.\n",
    "    \n",
    "    Args:\n",
    "        letter (str): The letter to extract authors for.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing author information.\n",
    "    \"\"\"\n",
    "    print(f\"Scraping authors for letter: {letter}\")\n",
    "    \n",
    "    # The correct URL format based on your sample\n",
    "    url = f\"https://www.gutenberg.org/browse/authors/{letter}.html.utf8\"\n",
    "    print(f\"Fetching {url}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch {url}. Status code: {response.status_code}\")\n",
    "            return []\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Find the div containing author listings\n",
    "        author_div = soup.find(\"div\", class_=\"pgdbbyauthor\")\n",
    "        \n",
    "        if not author_div:\n",
    "            print(\"Could not find author listings div\")\n",
    "            return []\n",
    "        \n",
    "        authors = []\n",
    "        \n",
    "        # Find all h2 elements (author headings)\n",
    "        author_headings = author_div.find_all(\"h2\")\n",
    "        \n",
    "        for heading in author_headings:\n",
    "            # Skip \"See:\" references\n",
    "            if \"See:\" in heading.text:\n",
    "                continue\n",
    "            \n",
    "            # Get author name - extract from heading text or anchor\n",
    "            author_name = None\n",
    "            author_id = None\n",
    "            \n",
    "            # Look for anchor with name attribute\n",
    "            anchor = heading.find(\"a\", attrs={\"name\": True})\n",
    "            if anchor:\n",
    "                author_id = anchor.get(\"name\")\n",
    "                # Clean up the author name by removing the permalink symbol\n",
    "                author_name = heading.text.replace(\"Â¶\", \"\").strip()\n",
    "            else:\n",
    "                # If no anchor with name, just use the heading text\n",
    "                author_name = heading.text.strip()\n",
    "            \n",
    "            if not author_name:\n",
    "                continue\n",
    "            \n",
    "            # Find the ul that follows this heading\n",
    "            author_ul = heading.find_next(\"ul\")\n",
    "            if not author_ul:\n",
    "                print(f\"No book list found for {author_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Count books in English where the author is listed as \"Author\"\n",
    "            book_count = 0\n",
    "            books = []\n",
    "            \n",
    "            # Find all li elements with class pgdbetext (etext entries)\n",
    "            book_items = author_ul.find_all(\"li\", class_=\"pgdbetext\")\n",
    "            \n",
    "            for item in book_items:\n",
    "                book_link = item.find(\"a\")\n",
    "                if not book_link:\n",
    "                    continue\n",
    "                    \n",
    "                book_title = book_link.text.strip()\n",
    "                book_url = book_link.get(\"href\")\n",
    "                \n",
    "                # Check if book is in English and author is listed as Author\n",
    "                item_text = item.text.lower()\n",
    "                if \"(english)\" in item_text and \"(as author)\" in item_text:\n",
    "                    book_count += 1\n",
    "                    books.append({\n",
    "                        \"title\": book_title,\n",
    "                        \"url\": f\"https://www.gutenberg.org{book_url}\" if book_url.startswith(\"/\") else book_url\n",
    "                    })\n",
    "            \n",
    "            if book_count > 0:\n",
    "                print(f\"Author: {author_name} - {book_count} English books as Author\")\n",
    "                authors.append({\n",
    "                    \"id\": author_id,\n",
    "                    \"name\": author_name,\n",
    "                    \"book_count\": book_count,\n",
    "                    \"books\": books\n",
    "                })\n",
    "        \n",
    "        return authors\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping letter {letter}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_prolific_authors(min_books=7, letters=None):\n",
    "    \"\"\"\n",
    "    Gets a list of authors with at least the specified number of books.\n",
    "    \n",
    "    Args:\n",
    "        min_books (int): Minimum number of books an author must have.\n",
    "        letters (list): List of letters to scrape. If None, all letters are scraped.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of dictionaries containing author information.\n",
    "    \"\"\"\n",
    "    if letters is None:\n",
    "        # All lowercase letters plus 'other'\n",
    "        letters = list('abcdefghijklmnopqrstuvwxyz') + ['other']\n",
    "    \n",
    "    prolific_authors = []\n",
    "    \n",
    "    for letter in letters:\n",
    "        authors = get_authors_from_letter(letter)\n",
    "        \n",
    "        # Filter for prolific authors\n",
    "        letter_prolific = [author for author in authors if author['book_count'] >= min_books]\n",
    "        prolific_authors.extend(letter_prolific)\n",
    "        \n",
    "        print(f\"Found {len(letter_prolific)} prolific authors for letter '{letter}'\")\n",
    "        \n",
    "        # Be nice to the server\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Sort by book count (descending)\n",
    "    prolific_authors.sort(key=lambda x: x['book_count'], reverse=True)\n",
    "    \n",
    "    return prolific_authors\n",
    "\n",
    "def save_author_list(authors, language, min_books):\n",
    "    \"\"\"\n",
    "    Saves the list of authors to a text file with a dynamic filename based on language and min_books.\n",
    "    \n",
    "    Args:\n",
    "        authors (list): List of author dictionaries.\n",
    "        language (str): The language used for filtering.\n",
    "        min_books (int): The minimum number of books used for filtering.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the folder if it doesn't exist\n",
    "        input_files_dir = \"data/input_files\"\n",
    "        os.makedirs(input_files_dir, exist_ok=True)\n",
    "\n",
    "        # Generate the filename based on language and minimum number of books\n",
    "        filename = os.path.join(input_files_dir, f\"{language}_{min_books}books.txt\")\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Found {len(authors)} prolific authors:\\n\\n\")\n",
    "            \n",
    "            for i, author in enumerate(authors):\n",
    "                f.write(f\"{i+1}. {author['name']} - {author['book_count']} books\\n\")\n",
    "                \n",
    "        print(f\"Author list saved to {filename}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving author list: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f958df42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
